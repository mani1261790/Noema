{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import math\nimport random\nfrom statistics import mean\n\nrandom.seed(33)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# VAE（Variational Autoencoder）\n\nVAEは、オートエンコーダの「再構成能力」に、生成モデルとしての「サンプリング可能性」を加えたモデルです。潜在変数を確率分布で扱うことで、学習後に新しいデータを生成できるのが最大の特徴です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "まず、なぜ普通のオートエンコーダだけでは不十分かを整理します。\n\n通常のAEは `x -> z -> x_hat` の再構成は上手でも、潜在空間 `z` がバラバラだと「どこからサンプルを引けば自然なデータが出るか」が分かりません。VAEはここに事前分布 `p(z)` を入れて、潜在空間を生成に使える形へ整えます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. VAEの最小数式\n\nVAEでは次の3つを同時に扱います。\n\n- エンコーダ（近似事後分布）: `q_phi(z|x)`\n- デコーダ（生成分布）: `p_theta(x|z)`\n- 潜在の事前分布: `p(z)=N(0,I)`\n\n学習目標はELBO最大化で、次の2項に分かれます。\n\n- 再構成項: `E_{q_phi(z|x)}[log p_theta(x|z)]`\n- 正則化項: `KL(q_phi(z|x) || p(z))`\n\n要するに、再構成を良くしつつ、潜在分布を標準正規に寄せる、という設計です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def gaussian_log_prob(x, mu, var):\n    var = max(var, 1e-8)\n    return -0.5 * ((x - mu) ** 2 / var + math.log(2 * math.pi * var))\n\n\ndef kl_normal_to_standard(mu, logvar):\n    # KL( N(mu, sigma^2) || N(0,1) )\n    return 0.5 * (mu * mu + math.exp(logvar) - 1.0 - logvar)\n\n\nx = 1.2\nmu_dec = 1.0\nvar_dec = 0.3\nmu_enc = 0.4\nlogvar_enc = -0.2\n\nrecon = gaussian_log_prob(x, mu_dec, var_dec)\nkl = kl_normal_to_standard(mu_enc, logvar_enc)\nelbo = recon - kl\n\nprint('reconstruction term =', round(recon, 4))\nprint('KL term             =', round(kl, 4))\nprint('ELBO                =', round(elbo, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 再パラメータ化トリック\n\n`z ~ q_phi(z|x)` をそのままサンプリングすると、勾配が流しにくくなります。VAEでは\n\n`z = mu + sigma * eps, eps ~ N(0,1)`\n\nと書き換え、乱数を `eps` 側へ分離します。これにより `mu, sigma`（=ネットワーク出力）へ勾配を通せます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def reparameterize(mu, logvar, eps):\n    sigma = math.exp(0.5 * logvar)\n    return mu + sigma * eps\n\n\nmu = 0.7\nlogvar = -0.8\neps_samples = [random.gauss(0.0, 1.0) for _ in range(5)]\nzs = [reparameterize(mu, logvar, e) for e in eps_samples]\n\nprint('eps samples =', [round(e, 3) for e in eps_samples])\nprint('z samples   =', [round(z, 3) for z in zs])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 1次元トイデータでVAEを学習する\n\nここではPyTorchを使わず、あえて超小型モデルを手書きで最適化します。目的は、VAEの損失構造（再構成 vs KL）を体感することです。\n\n- エンコーダ: `mu(x)=a*x+b`, `logvar(x)=c*x+d`\n- デコーダ: `x_hat(z)=m*z+n`\n\n学習は有限差分で行い、目的関数（再構成項 - beta * KL）を直接最大化します（教育用）。\n注意: このトイモデルは線形デコーダなので表現力を意図的に制限しています。2峰性データを完全に表現するのが目的ではなく、VAEの学習原理を確認するための設定です。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def make_toy_data(n1=60, n2=60):\n    left = [random.gauss(-2.0, 0.45) for _ in range(n1)]\n    right = [random.gauss(2.2, 0.55) for _ in range(n2)]\n    return left + right\n\n\ndata = make_toy_data()\nprint('dataset size =', len(data))\nprint('mean(data)   =', round(mean(data), 3))\nprint('min/max      =', round(min(data), 3), round(max(data), 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def encode(x, params):\n    a, b, c, d, _, _ = params\n    mu = a * x + b\n    logvar = c * x + d\n    logvar = max(min(logvar, 4.0), -6.0)  # 数値安定\n    return mu, logvar\n\n\ndef decode(z, params):\n    _, _, _, _, m, n = params\n    return m * z + n\n\n\ndef elbo_dataset(data, params, beta=1.0, recon_var=0.25, eps_list=None):\n    # recon_var: p_theta(x|z)=N(x_hat, recon_var) の固定分散\n    # 小さいほど再構成誤差に厳しくなる\n    if eps_list is None:\n        # 通常のモンテカルロ近似では毎回epsをサンプルする\n        eps_list = [random.gauss(0.0, 1.0) for _ in range(len(data))]\n\n    recon_terms = []\n    kl_terms = []\n    objectives = []\n\n    for x, eps in zip(data, eps_list):\n        mu, logvar = encode(x, params)\n        z = reparameterize(mu, logvar, eps)\n        x_hat = decode(z, params)\n\n        recon = gaussian_log_prob(x, x_hat, recon_var)\n        kl = kl_normal_to_standard(mu, logvar)\n        obj = recon - beta * kl\n\n        recon_terms.append(recon)\n        kl_terms.append(kl)\n        objectives.append(obj)\n\n    return mean(objectives), mean(recon_terms), mean(kl_terms)\n\n\nparams0 = [0.2, 0.0, -0.1, -0.5, 0.7, 0.0]\nfixed_eps = [random.gauss(0.0, 1.0) for _ in range(len(data))]\n\nobj0, recon0, kl0 = elbo_dataset(data, params0, beta=1.0, eps_list=fixed_eps)\nprint('initial objective =', round(obj0, 4))\nprint('initial recon=', round(recon0, 4), 'initial KL=', round(kl0, 4))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def finite_diff_grad(data, params, beta, recon_var, eps_list, h=1e-3):\n    grads = [0.0] * len(params)\n    for i in range(len(params)):\n        p_plus = params[:]\n        p_minus = params[:]\n        p_plus[i] += h\n        p_minus[i] -= h\n\n        f_plus, _, _ = elbo_dataset(data, p_plus, beta=beta, recon_var=recon_var, eps_list=eps_list)\n        f_minus, _, _ = elbo_dataset(data, p_minus, beta=beta, recon_var=recon_var, eps_list=eps_list)\n        grads[i] = (f_plus - f_minus) / (2 * h)\n    return grads\n\n\ndef train_toy_vae(data, beta=1.0, steps=120, lr=0.03, recon_var=0.25):\n    params = [0.2, 0.0, -0.1, -0.5, 0.7, 0.0]  # a,b,c,d,m,n\n\n    # 有限差分のノイズを減らすため、共通乱数(common random numbers)でepsを固定\n    eps_list = [random.gauss(0.0, 1.0) for _ in range(len(data))]\n\n    trace = []\n    for t in range(steps):\n        grads = finite_diff_grad(data, params, beta, recon_var, eps_list)\n        for i in range(len(params)):\n            params[i] += lr * grads[i]  # objective最大化\n\n        obj, recon, kl = elbo_dataset(data, params, beta=beta, recon_var=recon_var, eps_list=eps_list)\n        trace.append((obj, recon, kl))\n\n        if t % 20 == 0 or t == steps - 1:\n            print(f'step={t:03d} objective={obj:.4f} recon={recon:.4f} KL={kl:.4f}')\n\n    return params, trace\n\n\nparams_beta1, trace_beta1 = train_toy_vae(data, beta=1.0, steps=140, lr=0.025, recon_var=0.30)\nprint('trained params (beta=1) =', [round(v, 4) for v in params_beta1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "上のログで、目的関数（recon - beta * KL）が改善しつつ、再構成項とKL項のバランスが動くことが確認できます。これがVAE学習のダイナミクスです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. beta-VAEでトレードオフを見る\n\n`beta` を大きくするとKLを強く罰するため、潜在分布は事前分布に近づきます。その代わり再構成が悪化しやすくなります。\n\n注意: `beta` を変えると目的関数そのものが変わるので、`objective` 値を横比較して優劣を決めるのは不適切です。比較は主に再構成項とKL項で行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "params_beta4, trace_beta4 = train_toy_vae(data, beta=4.0, steps=140, lr=0.02, recon_var=0.30)\n\nfinal1 = trace_beta1[-1]\nfinal4 = trace_beta4[-1]\n\nprint('beta=1 final: objective={:.4f}, recon={:.4f}, KL={:.4f}'.format(*final1))\nprint('beta=4 final: objective={:.4f}, recon={:.4f}, KL={:.4f}'.format(*final4))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def summarize_latent_stats(data, params):\n    mus = []\n    vars_ = []\n    for x in data:\n        mu, logvar = encode(x, params)\n        mus.append(mu)\n        vars_.append(math.exp(logvar))\n\n    emu = mean(mus)\n    emu2 = mean(m * m for m in mus)\n    evar = mean(vars_)\n    return emu, emu2, evar\n\n\nmu1, mu21, var1 = summarize_latent_stats(data, params_beta1)\nmu4, mu24, var4 = summarize_latent_stats(data, params_beta4)\n\nprint('latent summary beta=1: E[mu]=', round(mu1, 4), 'E[mu^2]=', round(mu21, 4), 'E[var]=', round(var1, 4))\nprint('latent summary beta=4: E[mu]=', round(mu4, 4), 'E[mu^2]=', round(mu24, 4), 'E[var]=', round(var4, 4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`beta` を上げると、`q(z|x)` が標準正規に近づきやすくなり、潜在空間は整いますが、入力ごとの情報を削りすぎると再構成が崩れます。この綱引きを調整するのがbeta-VAEの本質です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 生成と補間\n\n学習後は `z ~ N(0,1)` を引いてデコーダに通すと新サンプルを生成できます。また、2つの入力の潜在平均を線形補間してデコードすると、連続的な変化を観察できます。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def generate_from_prior(params, n=8):\n    out = []\n    for _ in range(n):\n        z = random.gauss(0.0, 1.0)\n        x_hat = decode(z, params)\n        out.append((z, x_hat))\n    return out\n\n\ngen = generate_from_prior(params_beta1, n=10)\nprint('samples from prior z~N(0,1):')\nfor z, xh in gen:\n    print('z=', round(z, 3), '-> x_hat=', round(xh, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def latent_mean(x, params):\n    mu, _ = encode(x, params)\n    return mu\n\nx_a = data[5]\nx_b = data[-5]\nmu_a = latent_mean(x_a, params_beta1)\nmu_b = latent_mean(x_b, params_beta1)\n\nprint('x_a=', round(x_a, 3), 'mu_a=', round(mu_a, 3))\nprint('x_b=', round(x_b, 3), 'mu_b=', round(mu_b, 3))\nprint('interpolation in latent mean:')\n\nfor t in [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]:\n    z = (1 - t) * mu_a + t * mu_b\n    x_hat = decode(z, params_beta1)\n    print('t=', round(t, 1), 'z=', round(z, 3), 'x_hat=', round(x_hat, 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. よくある失敗: Posterior Collapse\n\nKLを強くしすぎたり、デコーダが強すぎたりすると、`q(z|x)` がほぼ `N(0,1)` になって入力情報を使わなくなることがあります。これをposterior collapseと呼びます。\n\n対策としては、KL warm-up、free bits、デコーダ容量調整、学習率調整などが使われます。\n\n注意: 実務での厳密判定は、KL値だけでは不十分です。`I(x;z)`（相互情報量）や、潜在をシャッフルしたときの再構成劣化など、情報保持の指標を併用します。ここで示す判定は教育用ヒューリスティックで、collapseの必要条件でも十分条件でもありません。\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# collapse の簡易判定（toy）: KLが極端に小さく、再構成が悪化していないか\n# 厳密判定ではなく、兆候を見るための簡易チェック（必要条件・十分条件ではない）\nkl_beta1 = trace_beta1[-1][2]\nkl_beta4 = trace_beta4[-1][2]\nrecon_beta1 = trace_beta1[-1][1]\nrecon_beta4 = trace_beta4[-1][1]\n\nprint('final KL beta=1 =', round(kl_beta1, 6), '| recon=', round(recon_beta1, 6))\nprint('final KL beta=4 =', round(kl_beta4, 6), '| recon=', round(recon_beta4, 6))\n\nif kl_beta4 < 0.01 and recon_beta4 < recon_beta1 - 0.3:\n    print('beta=4 run: collapse risk is high (toy criterion).')\nelse:\n    print('beta=4 run: collapse risk is not extreme in this toy run.')\n\nprint('For strict diagnosis, add mutual-information or ablation-based checks.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "VAEを一言で言うと、「再構成したい」という要求と「生成しやすい潜在空間にしたい」という要求を、ELBOで同時に満たすモデルです。\n\nこの後のGANや拡散モデルに進むときも、何を近似し、どの損失でその近似を押すのか、という観点で比較すると整理しやすくなります。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
