{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 機械学習のためのSQL\n\n機械学習では、モデル選択より前にデータを正しく整形することが重要です。\n実務ではその整形の多くを SQL で行います。SQL で作った特徴量は再現しやすく、学習環境と本番環境の差も小さくできます。\n\nこのノートでは、ECサービスの行動データを題材に、SQL の基本操作から、リークを避けた特徴量テーブル作成までを一気通貫で確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\nfrom datetime import datetime, timedelta\nfrom random import Random\nfrom textwrap import dedent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "まずはメモリ上にデータベースを作り、`users`, `events`, `orders` の3テーブルを定義します。\n`events` は行動ログ、`orders` は購入履歴、`users` は属性情報です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn = sqlite3.connect(\":memory:\")\nconn.row_factory = sqlite3.Row\ncur = conn.cursor()\n\ncur.executescript(\n    dedent(\n        \"\"\"\n        CREATE TABLE users (\n            user_id INTEGER PRIMARY KEY,\n            signup_date TEXT NOT NULL,\n            plan TEXT NOT NULL,\n            country TEXT NOT NULL\n        );\n\n        CREATE TABLE events (\n            event_id INTEGER PRIMARY KEY AUTOINCREMENT,\n            user_id INTEGER NOT NULL,\n            event_time TEXT NOT NULL,\n            event_type TEXT NOT NULL,\n            session_seconds INTEGER NOT NULL,\n            clicks INTEGER NOT NULL,\n            FOREIGN KEY (user_id) REFERENCES users(user_id)\n        );\n\n        CREATE TABLE orders (\n            order_id INTEGER PRIMARY KEY AUTOINCREMENT,\n            user_id INTEGER NOT NULL,\n            order_time TEXT NOT NULL,\n            amount REAL NOT NULL,\n            FOREIGN KEY (user_id) REFERENCES users(user_id)\n        );\n        \"\"\"\n    )\n)\nconn.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def q(sql: str, params=()):\n    return conn.execute(dedent(sql), params).fetchall()\n\n\ndef show(rows, limit=8):\n    rows = list(rows)\n    if not rows:\n        print(\"(no rows)\")\n        return\n    cols = rows[0].keys()\n    print(\" | \".join(cols))\n    print(\"-\" * 100)\n    for r in rows[:limit]:\n        print(\" | \".join(str(r[c]) for c in cols))\n    if len(rows) > limit:\n        print(f\"... ({len(rows)} rows total)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "以降は次の2つの関数を使います。\n\n- `q(sql, params)`: SQLを実行して結果行を返す\n- `show(rows)`: 結果を見やすく表示する\n\n例: `show(q(\"SELECT COUNT(*) AS n FROM users\"))`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に、分析用の疑似データを生成します。セルを3つに分けて、\n`ユーザー生成 → イベント生成 → 注文生成` の順で作ります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rng = Random(42)\nstart = datetime(2024, 1, 1)\nend = datetime(2024, 6, 30)\n\nplans = [\"free\", \"pro\", \"team\"]\nplan_weights = [0.62, 0.30, 0.08]\ncountries = [\"JP\", \"US\", \"IN\", \"DE\", \"FR\"]\n\nn_users = 320\nfor user_id in range(1, n_users + 1):\n    signup = start + timedelta(days=rng.randint(0, 80))\n    plan = rng.choices(plans, weights=plan_weights, k=1)[0]\n    country = rng.choice(countries)\n    cur.execute(\n        \"INSERT INTO users (user_id, signup_date, plan, country) VALUES (?, ?, ?, ?)\",\n        (user_id, signup.date().isoformat(), plan, country),\n    )\n\nconn.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for row in q(\"SELECT user_id, plan, signup_date FROM users\"):\n    user_id = row[\"user_id\"]\n    plan = row[\"plan\"]\n    signup_dt = datetime.fromisoformat(row[\"signup_date\"])\n\n    base_events = 20 if plan == \"free\" else 34 if plan == \"pro\" else 46\n    n_events = max(8, int(rng.gauss(base_events, 6)))\n\n    for _ in range(n_events):\n        day_offset = rng.randint(0, 178)\n        event_dt = signup_dt + timedelta(days=day_offset, hours=rng.randint(0, 23), minutes=rng.randint(0, 59))\n        if event_dt > end:\n            continue\n\n        if plan == \"free\":\n            clicks = max(0, int(rng.gauss(2.2, 1.4)))\n            session_seconds = max(20, int(rng.gauss(130, 70)))\n        elif plan == \"pro\":\n            clicks = max(0, int(rng.gauss(4.8, 2.0)))\n            session_seconds = max(30, int(rng.gauss(220, 90)))\n        else:\n            clicks = max(0, int(rng.gauss(6.5, 2.4)))\n            session_seconds = max(40, int(rng.gauss(290, 110)))\n\n        event_type = rng.choices(\n            [\"page_view\", \"search\", \"add_to_cart\"],\n            weights=[0.62, 0.25, 0.13],\n            k=1,\n        )[0]\n\n        cur.execute(\n            \"\"\"\n            INSERT INTO events (user_id, event_time, event_type, session_seconds, clicks)\n            VALUES (?, ?, ?, ?, ?)\n            \"\"\",\n            (user_id, event_dt.isoformat(sep=\" \"), event_type, session_seconds, clicks),\n        )\n\nconn.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "activity = q(\n    \"\"\"\n    SELECT\n        u.user_id,\n        u.plan,\n        u.signup_date,\n        COALESCE(COUNT(e.event_id), 0) AS event_count,\n        COALESCE(SUM(e.clicks), 0) AS total_clicks\n    FROM users u\n    LEFT JOIN events e ON u.user_id = e.user_id\n    GROUP BY u.user_id, u.plan, u.signup_date\n    \"\"\"\n)\n\nfor r in activity:\n    user_id = r[\"user_id\"]\n    plan = r[\"plan\"]\n    signup_dt = datetime.fromisoformat(r[\"signup_date\"])\n    total_clicks = r[\"total_clicks\"]\n    event_count = r[\"event_count\"]\n\n    base_prob = 0.02\n    if plan == \"pro\":\n        base_prob += 0.08\n    if plan == \"team\":\n        base_prob += 0.12\n    base_prob += min(0.35, total_clicks / 380.0)\n    base_prob += min(0.20, event_count / 420.0)\n\n    n_orders = 0\n    for _ in range(3):\n        if rng.random() < base_prob:\n            n_orders += 1\n\n    min_order_dt = signup_dt + timedelta(days=1)\n    max_order_dt = min(end, signup_dt + timedelta(days=180))\n    if min_order_dt > max_order_dt:\n        continue\n\n    total_seconds = int((max_order_dt - min_order_dt).total_seconds())\n\n    for _ in range(n_orders):\n        offset_sec = rng.randint(0, total_seconds)\n        order_dt = min_order_dt + timedelta(seconds=offset_sec)\n\n        mean_amount = 38 if plan == \"free\" else 74 if plan == \"pro\" else 130\n        amount = max(8, round(rng.gauss(mean_amount, mean_amount * 0.35), 2))\n\n        cur.execute(\n            \"INSERT INTO orders (user_id, order_time, amount) VALUES (?, ?, ?)\",\n            (user_id, order_dt.isoformat(sep=\" \"), amount),\n        )\n\nconn.commit()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "table_counts = q(\n    \"\"\"\n    SELECT 'users' AS table_name, COUNT(*) AS n FROM users\n    UNION ALL\n    SELECT 'events' AS table_name, COUNT(*) AS n FROM events\n    UNION ALL\n    SELECT 'orders' AS table_name, COUNT(*) AS n FROM orders\n    \"\"\"\n)\nshow(table_counts)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ここから SQL の基本操作を確認します。\nまずは `WHERE` と `ORDER BY` で、特定ユーザーのイベント履歴を時系列に取得します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = q(\n    \"\"\"\n    SELECT user_id, event_time, event_type, session_seconds, clicks\n    FROM events\n    WHERE user_id = ?\n    ORDER BY event_time\n    LIMIT 10\n    \"\"\",\n    (12,),\n)\nshow(rows)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に `GROUP BY` でユーザー単位の集計を作ります。\nこの集計はそのまま特徴量の候補になります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "agg = q(\n    \"\"\"\n    SELECT\n        user_id,\n        COUNT(*) AS n_events,\n        SUM(clicks) AS total_clicks,\n        AVG(session_seconds) AS avg_session_seconds\n    FROM events\n    GROUP BY user_id\n    HAVING COUNT(*) >= 18\n    ORDER BY total_clicks DESC\n    LIMIT 10\n    \"\"\"\n)\nshow(agg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`JOIN` と `CASE WHEN` を使うと、属性と行動を組み合わせた特徴量を作れます。\nこの例では、ある時点（`asof_ts`）より前90日間の購入金額を集計し、プランを数値化します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "asof_ts = '2024-05-01 00:00:00'\n\njoined = q(\n    \"\"\"\n    WITH spend_90 AS (\n      SELECT\n          user_id,\n          SUM(amount) AS spend_90d\n      FROM orders\n      WHERE order_time >= datetime(:asof_ts, '-90 day')\n        AND order_time < :asof_ts\n      GROUP BY user_id\n    )\n    SELECT\n        u.user_id,\n        u.plan,\n        CASE WHEN u.plan = 'free' THEN 0 ELSE 1 END AS paid_flag,\n        COALESCE(s.spend_90d, 0) AS spend_90d\n    FROM users u\n    LEFT JOIN spend_90 s ON u.user_id = s.user_id\n    ORDER BY spend_90d DESC\n    LIMIT 12\n    \"\"\",\n    {\"asof_ts\": asof_ts},\n)\nshow(joined)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ここから機械学習用テーブルを作ります。\n\n時点の定義:\n- `snapshot`: 予測時点\n- 特徴量窓: `snapshot` より前30日\n- ラベル窓: `snapshot` 以上かつ `snapshot+30日` 未満"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "snapshot = '2024-05-01 00:00:00'\nhorizon_days = 30\n\nfeature_sql = \"\"\"\nWITH event_30d AS (\n    SELECT\n        user_id,\n        COUNT(*) AS events_30d,\n        SUM(clicks) AS clicks_30d,\n        AVG(session_seconds) AS avg_session_30d,\n        MAX(event_time) AS last_event_time\n    FROM events\n    WHERE event_time < :snapshot\n      AND event_time >= datetime(:snapshot, '-30 day')\n    GROUP BY user_id\n),\norder_90d AS (\n    SELECT\n        user_id,\n        SUM(amount) AS spend_90d\n    FROM orders\n    WHERE order_time < :snapshot\n      AND order_time >= datetime(:snapshot, '-90 day')\n    GROUP BY user_id\n),\nlabel_window AS (\n    SELECT\n        user_id,\n        CASE WHEN COUNT(*) > 0 THEN 1 ELSE 0 END AS purchased_30d\n    FROM orders\n    WHERE order_time >= :snapshot\n      AND order_time < datetime(:snapshot, '+' || :horizon_days || ' day')\n    GROUP BY user_id\n)\nSELECT\n    u.user_id,\n    u.country,\n    CASE WHEN u.plan = 'free' THEN 0 ELSE 1 END AS paid_flag,\n    COALESCE(e.events_30d, 0) AS events_30d,\n    COALESCE(e.clicks_30d, 0) AS clicks_30d,\n    COALESCE(e.avg_session_30d, 0) AS avg_session_30d,\n    -- イベントがないユーザーは signup_date を最終行動日として扱う\n    CAST((julianday(:snapshot) - julianday(COALESCE(e.last_event_time, u.signup_date))) AS INTEGER) AS days_since_last_event,\n    COALESCE(o.spend_90d, 0) AS spend_90d,\n    COALESCE(l.purchased_30d, 0) AS label\nFROM users u\nLEFT JOIN event_30d e ON u.user_id = e.user_id\nLEFT JOIN order_90d o ON u.user_id = o.user_id\nLEFT JOIN label_window l ON u.user_id = l.user_id\nORDER BY u.user_id\n\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_rows = q(feature_sql, {\"snapshot\": snapshot, \"horizon_days\": horizon_days})\nshow(feature_rows, limit=12)\nprint('rows:', len(feature_rows))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_dist_sql = f\"\"\"\nWITH base AS (\n{feature_sql}\n)\nSELECT\n    label,\n    COUNT(*) AS n_users,\n    ROUND(AVG(events_30d), 2) AS avg_events_30d,\n    ROUND(AVG(spend_90d), 2) AS avg_spend_90d\nFROM base\nGROUP BY label\nORDER BY label\n\"\"\"\n\nlabel_dist = q(label_dist_sql, {\"snapshot\": snapshot, \"horizon_days\": horizon_days})\nshow(label_dist)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に、リークの例を確認します。\n比較を明確にするため、窓幅はどちらも30日に固定し、未来を含むかどうかだけを変えます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_stats_sql = f\"\"\"\nWITH base AS (\n{feature_sql}\n)\nSELECT label, ROUND(AVG(events_30d), 2) AS avg_events\nFROM base\nGROUP BY label\nORDER BY label\n\"\"\"\n\nleaky_stats_sql = \"\"\"\nWITH event_30d_leaky AS (\n    SELECT\n        user_id,\n        COUNT(*) AS events_30d\n    FROM events\n    WHERE event_time >= :snapshot\n      -- NG: snapshot以降（未来）のイベントを特徴量に含める\n      AND event_time < datetime(:snapshot, '+' || :horizon_days || ' day')\n    GROUP BY user_id\n),\nlabel_window AS (\n    SELECT\n        user_id,\n        CASE WHEN COUNT(*) > 0 THEN 1 ELSE 0 END AS label\n    FROM orders\n    WHERE order_time >= :snapshot\n      AND order_time < datetime(:snapshot, '+' || :horizon_days || ' day')\n    GROUP BY user_id\n)\nSELECT\n    COALESCE(l.label, 0) AS label,\n    ROUND(AVG(COALESCE(e.events_30d, 0)), 2) AS avg_events\nFROM users u\nLEFT JOIN event_30d_leaky e ON u.user_id = e.user_id\nLEFT JOIN label_window l ON u.user_id = l.user_id\nGROUP BY COALESCE(l.label, 0)\nORDER BY label\n\"\"\"\n\nclean_stats = q(clean_stats_sql, {\"snapshot\": snapshot, \"horizon_days\": horizon_days})\nleaky_stats = q(leaky_stats_sql, {\"snapshot\": snapshot, \"horizon_days\": horizon_days})\n\nprint('clean feature mean by label')\nshow(clean_stats)\nprint('leaky feature mean by label')\nshow(leaky_stats)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最後に、学習用テーブルを分割できる形へ整えます。\n`%` は余り演算子で、`x % 5` は 0〜4 の fold 番号を作ります。\nここでは分かりやすさ優先で `user_id % 5` を使います（実務ではハッシュ関数を使うことが多いです）。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_fold_sql = f\"\"\"\nWITH base AS (\n{feature_sql}\n)\nSELECT\n    user_id,\n    paid_flag,\n    events_30d,\n    clicks_30d,\n    avg_session_30d,\n    days_since_last_event,\n    spend_90d,\n    label,\n    (user_id % 5) AS fold_id\nFROM base\nORDER BY user_id\n\"\"\"\n\ndataset_with_fold = q(dataset_fold_sql, {\"snapshot\": snapshot, \"horizon_days\": horizon_days})\nshow(dataset_with_fold, limit=12)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SQL は機械学習パイプラインの前工程ではなく、学習品質を決める中核です。\n特に重要なのは、ラベル時点と特徴量時点の境界を明示し、未来情報を混ぜないことです。\n\nモデルを変える前に、SQL で作る学習テーブルが「本番時点でも再現可能か」を必ず確認してください。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
