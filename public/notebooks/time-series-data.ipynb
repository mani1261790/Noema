{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 時系列データの扱い\n\n時系列データは、表の1行1行が独立ではなく、時間順でつながっています。\nこの順序を無視して分割や特徴量設計をすると、評価だけ高くて本番で崩れるモデルになりやすくなります。\n\nこのノートでは、売上の1ステップ先予測を題材に、観察、特徴量化、リーク回避、評価、将来予測までを一気通貫で確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.base import clone\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.linear_model import Ridge\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import TimeSeriesSplit, cross_val_score, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "まず、上昇トレンド、季節性、キャンペーン効果を持つ疑似データを作ります。\n実データがなくても、構造を入れた疑似データを作って小さく検証すると、何が効くのかを読み取りやすくなります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\nrng = np.random.default_rng(7)\n\ndates = pd.date_range(\"2018-01-01\", periods=96, freq=\"MS\")\ntrend = np.linspace(0, 95, len(dates))\nseasonal = 18 * np.sin(2 * np.pi * np.arange(len(dates)) / 12)\npromo = (np.arange(len(dates)) % 6 == 0).astype(int)\nnoise = rng.normal(loc=0.0, scale=4.5, size=len(dates))\n\nsales = 220 + trend + seasonal + 16 * promo + noise\n\ndf = pd.DataFrame({\n    \"date\": dates,\n    \"sales\": sales,\n    \"promo\": promo,\n})\n\ndf.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(11, 4.4))\nax.plot(df[\"date\"], df[\"sales\"], color=\"#2b6cb0\", linewidth=2, label=\"sales\")\nax.scatter(\n    df.loc[df[\"promo\"] == 1, \"date\"],\n    df.loc[df[\"promo\"] == 1, \"sales\"],\n    color=\"#c05621\",\n    s=28,\n    label=\"promo month\",\n)\nax.plot(df[\"date\"], df[\"sales\"].rolling(12).mean(), color=\"#4a5568\", linewidth=1.6, label=\"12-month moving average\")\nax.set_title(\"Monthly Sales\")\nax.set_xlabel(\"date\")\nax.set_ylabel(\"sales\")\nax.legend(loc=\"upper left\")\nplt.tight_layout()\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "時系列予測で最重要なのは、「予測時点で使える情報だけ」で特徴量を作ることです。\nここでは `lag_1, lag_2, lag_3, lag_6, lag_12` と移動平均を作ります。\n`lag_12` を使うため先頭12か月は欠損となり、`dropna()` で除外されます。これは正常な挙動です。\n\nまた、月を 1〜12 の整数のまま使うと 12月と1月が遠く見えるため、`sin/cos` で円環的な季節性を表します。\n移動平均には `shift(1)` を入れ、当月値の混入を防いでリークを避けます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_time_features(frame: pd.DataFrame, lag_steps=(1, 2, 3, 6, 12), roll_windows=(3, 6)) -> pd.DataFrame:\n    out = frame.sort_values(\"date\").reset_index(drop=True).copy()\n\n    for lag in lag_steps:\n        out[f\"lag_{lag}\"] = out[\"sales\"].shift(lag)\n\n    for window in roll_windows:\n        out[f\"roll_mean_{window}\"] = out[\"sales\"].shift(1).rolling(window=window).mean()\n\n    month = out[\"date\"].dt.month\n    out[\"month_sin\"] = np.sin(2 * np.pi * month / 12)\n    out[\"month_cos\"] = np.cos(2 * np.pi * month / 12)\n\n    return out.dropna().reset_index(drop=True)\n\nfeature_df = make_time_features(df)\nfeature_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [\n    \"promo\",\n    \"month_sin\",\n    \"month_cos\",\n    \"lag_1\",\n    \"lag_2\",\n    \"lag_3\",\n    \"lag_6\",\n    \"lag_12\",\n    \"roll_mean_3\",\n    \"roll_mean_6\",\n]\n\nprint(\"raw period :\", df[\"date\"].min().date(), \"to\", df[\"date\"].max().date(), \"rows:\", len(df))\nprint(\"feat period:\", feature_df[\"date\"].min().date(), \"to\", feature_df[\"date\"].max().date(), \"rows:\", len(feature_df))\nprint(\"features:\", feature_cols)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "自己相関を見ると、「何か月前の値と似た動きをするか」が分かります。\n季節周期の候補やラグの当たりを付けるときに役立ちます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def autocorr_at_lag(values: np.ndarray, lag: int) -> float:\n    x = values[lag:]\n    y = values[:-lag]\n    if x.std() == 0 or y.std() == 0:\n        return 0.0\n    return float(np.corrcoef(x, y)[0, 1])\n\nseries = feature_df[\"sales\"].to_numpy()\nlags = np.arange(1, 25)\nautocorr_values = np.array([autocorr_at_lag(series, int(lag)) for lag in lags])\n\nfig, ax = plt.subplots(figsize=(10, 3.6))\nax.bar(lags, autocorr_values, color=\"#2f855a\")\nax.axhline(0, color=\"#1a202c\", linewidth=1)\nax.set_title(\"Autocorrelation by lag\")\nax.set_xlabel(\"lag\")\nax.set_ylabel(\"corr\")\nplt.tight_layout()\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ここからは、最後の12か月をテストに固定して評価します。\nまずは基準として、1か月前の値をそのまま予測に使う単純ベースラインを作ります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_horizon = 12\ntrain_df = feature_df.iloc[:-test_horizon].copy()\ntest_df = feature_df.iloc[-test_horizon:].copy()\n\nX_train = train_df[feature_cols]\ny_train = train_df[\"sales\"]\nX_test = test_df[feature_cols]\ny_test = test_df[\"sales\"]\n\nnaive_pred = test_df[\"lag_1\"].to_numpy()\nnaive_mae = mean_absolute_error(y_test, naive_pred)\nprint(f\"naive MAE: {naive_mae:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "対照として、やってはいけないランダム分割も試します。\nランダム分割では「後年のデータを学習に使いながら前の年をテストする」状態が起き、本番では使えない未来情報が暗黙に混ざります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_all = feature_df[feature_cols]\ny_all = feature_df[\"sales\"]\n\nX_tr_rand, X_te_rand, y_tr_rand, y_te_rand = train_test_split(\n    X_all, y_all, test_size=0.2, random_state=42, shuffle=True\n)\n\nrand_pipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"ridge\", Ridge(alpha=1.0)),\n])\nrand_pipeline.fit(X_tr_rand, y_tr_rand)\nrand_pred = rand_pipeline.predict(X_te_rand)\nrand_mae = mean_absolute_error(y_te_rand, rand_pred)\n\nprint(f\"random split ridge MAE (invalid for TS): {rand_mae:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次に、時系列順を守った1ステップ先予測（予測のたびに実測で更新する前提）でモデルを比較します。\n線形モデルは解釈しやすく、木モデルは非線形性を拾いやすいという違いがあります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_model = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"ridge\", Ridge(alpha=1.0)),\n])\n\nrf_model = RandomForestRegressor(\n    n_estimators=350,\n    max_depth=8,\n    min_samples_leaf=2,\n    random_state=42,\n    n_jobs=-1,\n)\n\nridge_model.fit(X_train, y_train)\nrf_model.fit(X_train, y_train)\n\nridge_pred = ridge_model.predict(X_test)\nrf_pred = rf_model.predict(X_test)\n\nridge_mae = mean_absolute_error(y_test, ridge_pred)\nrf_mae = mean_absolute_error(y_test, rf_pred)\n\nprint(f\"naive MAE                : {naive_mae:.3f}\")\nprint(f\"chronological ridge MAE  : {ridge_mae:.3f}\")\nprint(f\"chronological rf MAE     : {rf_mae:.3f}\")\nprint(f\"random split ridge MAE   : {rand_mae:.3f} (invalid setup)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "one_step_df = test_df[[\"date\", \"sales\"]].copy()\none_step_df[\"naive\"] = naive_pred\none_step_df[\"ridge\"] = ridge_pred\none_step_df[\"rf\"] = rf_pred\n\nfig, ax = plt.subplots(figsize=(11, 4.4))\nax.plot(one_step_df[\"date\"], one_step_df[\"sales\"], marker=\"o\", linewidth=2, label=\"actual\")\nax.plot(one_step_df[\"date\"], one_step_df[\"naive\"], marker=\"o\", linewidth=1.5, label=\"naive\")\nax.plot(one_step_df[\"date\"], one_step_df[\"ridge\"], marker=\"o\", linewidth=1.5, label=\"ridge\")\nax.plot(one_step_df[\"date\"], one_step_df[\"rf\"], marker=\"o\", linewidth=1.5, label=\"random forest\")\nax.set_title(\"One-Step Forecast (Observed Updates)\")\nax.set_xlabel(\"date\")\nax.set_ylabel(\"sales\")\nax.legend()\nplt.tight_layout()\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "固定起点で12か月先まで当てるには、逐次予測のバックテストが必要です。\nここでは学習期間を固定し、予測値を次月ラグへ入れながら12ステップ先まで進めます。\n`promo` は「6か月ごとに実施される既知の計画値」を使える前提にしています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict_next_months(history: pd.DataFrame, model, steps: int = 12) -> pd.DataFrame:\n    working = history.sort_values(\"date\").reset_index(drop=True).copy()\n    preds = []\n\n    for _ in range(steps):\n        next_date = (working[\"date\"].iloc[-1] + pd.offsets.MonthBegin(1)).normalize()\n        month_index = len(working)\n        next_promo = int(month_index % 6 == 0)\n\n        next_row = {\n            \"date\": next_date,\n            \"promo\": next_promo,\n            \"lag_1\": float(working[\"sales\"].iloc[-1]),\n            \"lag_2\": float(working[\"sales\"].iloc[-2]),\n            \"lag_3\": float(working[\"sales\"].iloc[-3]),\n            \"lag_6\": float(working[\"sales\"].iloc[-6]),\n            \"lag_12\": float(working[\"sales\"].iloc[-12]),\n            \"roll_mean_3\": float(working[\"sales\"].iloc[-3:].mean()),\n            \"roll_mean_6\": float(working[\"sales\"].iloc[-6:].mean()),\n            \"month_sin\": float(np.sin(2 * np.pi * next_date.month / 12)),\n            \"month_cos\": float(np.cos(2 * np.pi * next_date.month / 12)),\n        }\n\n        row_df = pd.DataFrame([next_row])\n        y_hat = float(model.predict(row_df[feature_cols])[0])\n\n        preds.append({\"date\": next_date, \"forecast\": y_hat})\n        working = pd.concat(\n            [working, pd.DataFrame([{\"date\": next_date, \"sales\": y_hat, \"promo\": next_promo}])],\n            ignore_index=True,\n        )\n\n    return pd.DataFrame(preds)\n\ntrain_raw = df.iloc[:-test_horizon].copy()\ntest_raw = df.iloc[-test_horizon:].copy()\ntrain_raw_feat = make_time_features(train_raw)\n\nridge_recursive = clone(ridge_model)\nrf_recursive = clone(rf_model)\nridge_recursive.fit(train_raw_feat[feature_cols], train_raw_feat[\"sales\"])\nrf_recursive.fit(train_raw_feat[feature_cols], train_raw_feat[\"sales\"])\n\nridge_backtest = predict_next_months(train_raw, ridge_recursive, steps=test_horizon)\nrf_backtest = predict_next_months(train_raw, rf_recursive, steps=test_horizon)\n\nridge_recursive_mae = mean_absolute_error(test_raw[\"sales\"], ridge_backtest[\"forecast\"])\nrf_recursive_mae = mean_absolute_error(test_raw[\"sales\"], rf_backtest[\"forecast\"])\n\nprint(f\"recursive ridge MAE (12-step): {ridge_recursive_mae:.3f}\")\nprint(f\"recursive rf MAE (12-step)   : {rf_recursive_mae:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recursive_plot = test_raw[[\"date\", \"sales\"]].copy()\nrecursive_plot[\"ridge_recursive\"] = ridge_backtest[\"forecast\"].to_numpy()\nrecursive_plot[\"rf_recursive\"] = rf_backtest[\"forecast\"].to_numpy()\n\nfig, ax = plt.subplots(figsize=(11, 4.4))\nax.plot(recursive_plot[\"date\"], recursive_plot[\"sales\"], marker=\"o\", linewidth=2, label=\"actual\")\nax.plot(recursive_plot[\"date\"], recursive_plot[\"ridge_recursive\"], marker=\"o\", linewidth=1.5, label=\"ridge recursive\")\nax.plot(recursive_plot[\"date\"], recursive_plot[\"rf_recursive\"], marker=\"o\", linewidth=1.5, label=\"rf recursive\")\nax.set_title(\"Recursive 12-Step Backtest\")\nax.set_xlabel(\"date\")\nax.set_ylabel(\"sales\")\nax.legend()\nplt.tight_layout()\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "分割1回だけでは偶然の影響が残るため、`TimeSeriesSplit` でウォークフォワード評価も確認します。\nこの評価では常に「過去で学習し未来を検証する」順序が守られます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tscv = TimeSeriesSplit(n_splits=5)\ncv_scores = cross_val_score(\n    ridge_model,\n    X_all,\n    y_all,\n    cv=tscv,\n    scoring=\"neg_mean_absolute_error\",\n)\n\ncv_mae = -cv_scores\nprint(\"TimeSeriesSplit MAE:\", np.round(cv_mae, 3))\nprint(\"mean:\", round(cv_mae.mean(), 3), \"std:\", round(cv_mae.std(), 3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "最後に運用想定として、利用可能な全期間で再学習して未来12か月を予測します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ridge_final = clone(ridge_model)\nridge_final.fit(X_all, y_all)\n\nfuture_pred = predict_next_months(df, ridge_final, steps=12)\nfuture_pred.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recent_hist = df.tail(24)\nfig, ax = plt.subplots(figsize=(11, 4.4))\nax.plot(recent_hist[\"date\"], recent_hist[\"sales\"], marker=\"o\", label=\"history (last 24 months)\")\nax.plot(future_pred[\"date\"], future_pred[\"forecast\"], marker=\"o\", label=\"future forecast (ridge)\")\nax.set_title(\"History and 12-Month Forecast\")\nax.set_xlabel(\"date\")\nax.set_ylabel(\"sales\")\nax.legend()\nplt.tight_layout()\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "時系列モデリングでは、モデルを複雑にする前に「時間順を壊していないか」を必ず確認してください。\nラグ特徴と移動平均のような基本設計でも、評価設計が正しければ実務で使える強い基準線になります。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
