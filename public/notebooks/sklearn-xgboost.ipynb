{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# scikit-learnとXGBoostの使い方\n\nscikit-learn は、前処理・学習・評価を統一された API で扱えるライブラリです。\nXGBoost は勾配ブースティングを高速かつ高精度に実装した手法で、タブularデータで強力な選択肢になります。\n\nこのノートでは、まず scikit-learn の基本フローを固め、その上で XGBoost を同じ問題に適用して比較します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n\ntry:\n    from xgboost import XGBClassifier\n    XGBOOST_AVAILABLE = True\nexcept ModuleNotFoundError:\n    XGBClassifier = None\n    XGBOOST_AVAILABLE = False\n\nsns.set_theme(style=\"whitegrid\", context=\"notebook\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. scikit-learnの基本フロー\n\nここでは乳がんデータセットを使って、\n`データ分割 → パイプライン定義 → 学習 → 評価` を一気通貫で実行します。\n\n評価指標は Accuracy と ROC-AUC を使います。\nAccuracy は分類の正解率、ROC-AUC は分類しきい値を動かしたときの識別性能（順位づけの上手さ）を見ます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cancer = load_breast_cancer(as_frame=True)\nX = cancer.data\ny = cancer.target\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nbaseline = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"model\", LogisticRegression(max_iter=2000, random_state=42)),\n])\n\nbaseline.fit(X_train, y_train)\npred = baseline.predict(X_test)\nproba = baseline.predict_proba(X_test)[:, 1]\n\nprint(f\"accuracy: {accuracy_score(y_test, pred):.3f}\")\nprint(f\"roc_auc : {roc_auc_score(y_test, proba):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "混同行列を確認すると、単純な精度だけでは見えない誤分類の偏りを把握できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, pred)\nfig, ax = plt.subplots(figsize=(4.5, 4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", cbar=False, ax=ax)\nax.set_title(\"Logistic Regression Confusion Matrix\")\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"Actual\")\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 交差検証とハイパーパラメータ探索\n\n分割1回の評価だけでは偶然の影響が残るので、交差検証で安定性を見ます。\nその後、`GridSearchCV` で `C` を探索します。\n\nここでの流れは次の通りです。\n- まず CV で、モデル設定が全体として安定しているかを確認\n- 次に訓練データ側で GridSearch を実行し、テストデータは最後まで未使用に保つ\n\nこうすることで、チューニング結果を過度に楽観視しにくくなります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv_scores = cross_val_score(\n    baseline,\n    X,\n    y,\n    cv=5,\n    scoring=\"roc_auc\",\n)\nprint(\"CV ROC-AUC (5-fold):\", np.round(cv_scores, 4))\nprint(\"mean:\", cv_scores.mean())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "search = GridSearchCV(\n    estimator=Pipeline([\n        (\"scaler\", StandardScaler()),\n        (\"model\", LogisticRegression(max_iter=2000, random_state=42)),\n    ]),\n    param_grid={\n        \"model__C\": [0.01, 0.1, 1.0, 3.0, 10.0],\n    },\n    cv=5,\n    scoring=\"roc_auc\",\n    n_jobs=-1,\n)\nsearch.fit(X_train, y_train)\n\nbest_lr = search.best_estimator_\nbest_pred = best_lr.predict(X_test)\nbest_proba = best_lr.predict_proba(X_test)[:, 1]\n\nprint(\"best params:\", search.best_params_)\nprint(f\"tuned accuracy: {accuracy_score(y_test, best_pred):.3f}\")\nprint(f\"tuned roc_auc : {roc_auc_score(y_test, best_proba):.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. XGBoostを同じ問題に適用する\n\nXGBoost が利用可能な環境では、同じ学習データで性能比較します。\nXGBoost は木ベースなので、今回の設定では標準化を必須としません。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if XGBOOST_AVAILABLE:\n    xgb = XGBClassifier(\n        n_estimators=300,\n        max_depth=4,\n        learning_rate=0.05,\n        subsample=0.9,\n        colsample_bytree=0.9,\n        eval_metric=\"logloss\",\n        random_state=42,\n    )\n    xgb.fit(X_train, y_train)\n\n    xgb_pred = xgb.predict(X_test)\n    xgb_proba = xgb.predict_proba(X_test)[:, 1]\n\n    print(f\"xgb accuracy: {accuracy_score(y_test, xgb_pred):.3f}\")\n    print(f\"xgb roc_auc : {roc_auc_score(y_test, xgb_proba):.3f}\")\nelse:\n    print(\"xgboost がインストールされていないため、このセルはスキップされました。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "XGBoost を使えた場合は、重要特徴量を見て学習がどこに注目したかを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if XGBOOST_AVAILABLE:\n    importances = pd.Series(xgb.feature_importances_, index=X.columns).sort_values(ascending=False).head(12)\n    fig, ax = plt.subplots(figsize=(7, 4.5))\n    sns.barplot(x=importances.values, y=importances.index, orient=\"h\", ax=ax)\n    ax.set_title(\"Top 12 Feature Importances (XGBoost)\")\n    ax.set_xlabel(\"importance\")\n    ax.set_ylabel(\"feature\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"xgboost 未導入のため、重要特徴量の表示をスキップしました。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 使い分けの実務メモ\n\n- scikit-learn: 実験の土台を作るのが速く、比較実験を回しやすい\n- XGBoost: 表形式データで高い精度を狙いやすい\n\nまず scikit-learn で前処理と評価設計を固め、\n次に XGBoost を含む複数モデルを同一条件で比較する流れが実践的です。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
