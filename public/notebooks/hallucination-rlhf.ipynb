{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ハルシネーションとRLHF\n\nLLM セクションの学習ステップ 5/8。\nハルシネーションとRLHFでは、モデル呼び出し以前に入力設計と評価設計を固める習慣を作ります。\n\nこのステップの到達目標: プロンプト、事前学習、微調整、RAG、効率化を実装視点で横断し、設計判断を言語化できる状態にします。\n前提: 確率的な予測モデルの見方と、深層学習の基礎が前提です。\n\n今回の中心語: 「トークン」、「事前学習」、「微調整」、「RAG」、「推論最適化」、「ハルシネーションとRLHF」\n前ステップ「ファインチューニング」では ファインチューニング対象文の準備 → プロンプトを構造化する を確認しました。\nここまでに登場した語: 「トークン」、「事前学習」、「微調整」、「RAG」、「推論最適化」、「プロンプトエンジニアリング」、「スケーリング則」、「ファインチューニング」\nセクション全体のゴール: プロンプト、事前学習、微調整、RAG、効率化を実装視点で横断し、設計判断を言語化できる状態にします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実験 1: ハルシネーション観測の基礎\n\n根拠欠落の回答を減らす観点で、入力長と情報密度をまず確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = '根拠が不足した回答は一見自然でも信頼性を損なう。'\nchar_len = len(text)\nspace_tokens = text.split()\nrough_tokens = max(1, char_len // 2)\nprint('task = hallucination-rlhf')\nprint('chars=', char_len, 'space_tokens=', len(space_tokens), 'rough_tokens=', rough_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "以降で評価軸と報酬設計に接続します。\n\nこの節では、トークン が入出力のどこを決めるかを中心に読める状態になれば十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実験 2: プロンプトを構造化する\n\n次に、指示・制約・出力形式を分離したテンプレートを作ります。曖昧さを減らすための実装技法です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "instruction = '勾配降下法を初学者向けに説明する'\nconstraints = ['120字以内', '比喩は1つまで', '最後に要点を1行でまとめる']\nprompt = f\"指示: {instruction}\\n制約: {'; '.join(constraints)}\\n出力:\"\nprint(prompt)\nprint('prompt_chars=', len(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "この形にすると、失敗原因を特定しやすくなります。品質改善は原因分離のしやすさで決まります。\n\nこの節では、トークン が入出力のどこを決めるかを中心に読める状態になれば十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 式と実装の往復\n\n1. $p_{\\theta}(x_t \\mid x_{<t})$\n2. $L_{CE} = -\\sum_t \\log p_{\\theta}(x_t \\mid x_{<t})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実験 3: 検索文脈を結合する\n\nここで RAG の最小形を実装します。質問と関連文を結合し、回答入力を作る流れを確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = 'ベルマン方程式を高校生向けに説明して'\nretrieved = ['価値は将来報酬の割引和で定義する', '現在価値は次状態価値で再帰的に更新できる']\ncontext = '\\n'.join(f'- {c}' for c in retrieved)\nfinal_input = f\"質問:\\n{question}\\n\\n参考文脈:\\n{context}\\n\\n回答:\"\nprint(final_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "検索文脈を入れる目的は、モデルの記憶に頼りすぎないことです。根拠付き応答を作りやすくなります。\n\nこの節では、トークン が入出力のどこを決めるかを中心に読める状態になれば十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実験 4: 評価項目を数値化する\n\n次に、回答を点検するための簡易スコアを定義します。評価軸を言語化すると改善が継続できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "answer = 'ベルマン方程式は、今の価値を次の価値で更新する再帰式です。'\nchecks = {'length_ok': len(answer) <= 120, 'has_keyword': '価値' in answer, 'has_recurrence': '再帰' in answer}\nscore = sum(1 for v in checks.values() if v) / len(checks)\nprint('checks=', checks)\nprint('score=', round(score, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "このような軽量評価でも、改善方向を揃える効果があります。実務ではこの評価軸をチームで共有します。\n\nこの節では、トークン が入出力のどこを決めるかを中心に読める状態になれば十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 実験 5: 推論コストを見積もる\n\n最後に、入力と出力の長さから概算コストを計算します。モデル選択は性能だけでなく費用とのバランスが必要です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_tokens = 320\noutput_tokens = 180\nprice_per_1k = 0.0012\ncost = (input_tokens + output_tokens) / 1000 * price_per_1k\nprint('estimated_cost=', round(cost, 6))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "この見積もりを運用前に作ると、スケール時の予算超過を防ぎやすくなります。\n\nこの節では、トークン が入出力のどこを決めるかを中心に読める状態になれば十分です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 振り返り\n\n今回のノートで押さえておくべき誤解しやすい点を整理します。\n\n1. プロンプトだけで全問題を解決しようとする\n2. 評価指標を決めずに改善を繰り返す\n3. コストと品質のバランスを見ない\n\n次は学習ステップ 6/8「Tool UseとRAG」へ進み、今回のコードとの差分を確認してください。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
