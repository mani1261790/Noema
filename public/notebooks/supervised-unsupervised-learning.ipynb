{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 教師あり学習と教師なし学習\n\n機械学習の入口で最初に分かれるのが「正解ラベルがあるかどうか」です。\n教師あり学習は、入力と正解の対応を学んで予測する枠組みです。教師なし学習は、正解がないデータから構造やまとまりを見つけます。\n\nこのノートでは、同じような数値データを使って両者を比較し、\nどんな問いにどちらを使うべきかを、コードと結果の対応で確認します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.datasets import make_classification, make_blobs, load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, silhouette_score\n\nsns.set_theme(style=\"whitegrid\", context=\"notebook\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 教師あり学習: ラベルありデータで予測する\n\nまずは二値分類データを作り、`0` と `1` を予測する問題を作ります。\nここでは「ラベルがある」ことが重要で、モデルはこのラベルを目標に学習します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X, y = make_classification(\n    n_samples=600,\n    n_features=6,\n    n_informative=4,\n    n_redundant=1,\n    class_sep=1.2,\n    random_state=42,\n)\n\nfeature_names = [f\"x{i}\" for i in range(X.shape[1])]\ndf_cls = pd.DataFrame(X, columns=feature_names)\ndf_cls[\"label\"] = y\n\ndf_cls.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "学習時に訓練データと評価データを分けるのは、汎化性能を確認するためです。\n評価データを分けずに性能を見ると、実運用での精度を過大評価しやすくなります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n    df_cls[feature_names],\n    df_cls[\"label\"],\n    test_size=0.25,\n    random_state=42,\n    stratify=df_cls[\"label\"],\n)\n\nclf = Pipeline([\n    (\"scaler\", StandardScaler()),\n    (\"model\", LogisticRegression(max_iter=1000, random_state=42)),\n])\nclf.fit(X_train, y_train)\n\npred = clf.predict(X_test)\nacc = accuracy_score(y_test, pred)\nprint(f\"test accuracy: {acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "分類では、正解率だけでなく混同行列を確認すると、\nどのクラスで間違っているかを具体的に把握できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, pred)\nfig, ax = plt.subplots(figsize=(4.5, 4))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\nax.set_title(\"Confusion Matrix\")\nax.set_xlabel(\"Predicted\")\nax.set_ylabel(\"Actual\")\nplt.show()\n\nprint(classification_report(y_test, pred, digits=3))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "標準化の有無で精度がどう変わるかを見ると、\n前処理がモデル性能に与える影響を体感できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_no_scale = LogisticRegression(max_iter=1000, random_state=42)\nclf_no_scale.fit(X_train, y_train)\npred_no_scale = clf_no_scale.predict(X_test)\n\nacc_no_scale = accuracy_score(y_test, pred_no_scale)\nprint(f\"without scaling: {acc_no_scale:.3f}\")\nprint(f\"with scaling   : {acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 教師なし学習: ラベルなしデータで構造を見つける\n\n次はクラスタリングです。ここでは学習時に正解ラベルを使いません。\n「似た点を同じグループにまとめる」こと自体が目的になります。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_blob, _ = make_blobs(\n    n_samples=450,\n    centers=3,\n    cluster_std=1.2,\n    n_features=2,\n    random_state=42,\n)\n\nfig, ax = plt.subplots(figsize=(5, 4))\nax.scatter(X_blob[:, 0], X_blob[:, 1], s=18, alpha=0.8)\nax.set_title(\"Unlabeled Data for Clustering\")\nax.set_xlabel(\"feature 1\")\nax.set_ylabel(\"feature 2\")\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "クラスタ数 `k` は先に与える必要があります。\n`inertia` と `silhouette` を併せて見ると、極端な `k` を避けやすくなります。\n\n- inertia: 各点と所属クラスタ中心の距離二乗和（小さいほどまとまりが良い）\n- silhouette: クラスタ内の近さとクラスタ間の離れ具合のバランス（-1〜1で高いほど良い）\n\ninertia は `k` を増やすと下がりやすいので、silhouette とセットで判断するのが実践的です。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\nfor k in range(2, 8):\n    km = KMeans(n_clusters=k, n_init=20, random_state=42)\n    labels = km.fit_predict(X_blob)\n    rows.append({\n        \"k\": k,\n        \"inertia\": km.inertia_,\n        \"silhouette\": silhouette_score(X_blob, labels)\n    })\n\nk_report = pd.DataFrame(rows)\nk_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ここでは `k=3` を選んで可視化します。\n教師ありと違い、評価は「正解と一致したか」ではなく、点群のまとまりの良さで判断します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "kmeans = KMeans(n_clusters=3, n_init=20, random_state=42)\ncluster_id = kmeans.fit_predict(X_blob)\ncenters = kmeans.cluster_centers_\n\nfig, ax = plt.subplots(figsize=(5.5, 4.2))\nscatter = ax.scatter(X_blob[:, 0], X_blob[:, 1], c=cluster_id, cmap=\"tab10\", s=22, alpha=0.8)\nax.scatter(centers[:, 0], centers[:, 1], c=\"black\", marker=\"X\", s=140, label=\"centers\")\nax.legend(loc=\"best\")\nax.set_title(\"KMeans Clustering (k=3)\")\nax.set_xlabel(\"feature 1\")\nax.set_ylabel(\"feature 2\")\nplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "教師なし学習の代表例として次元圧縮も確認します。\nPCA は「情報の分散が大きい方向」を優先して、特徴量を少数次元へ圧縮します。\n\nPCA は特徴量スケールに影響されるため、先に標準化してから実行するのが基本です。\n出力される `explained_variance_ratio_` は、各主成分が全体の分散の何割を説明しているかを表します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris = load_iris(as_frame=True)\nX_iris = iris.data\ny_iris = iris.target\n\nX_iris_scaled = StandardScaler().fit_transform(X_iris)\npca = PCA(n_components=2, random_state=42)\nX_iris_2d = pca.fit_transform(X_iris_scaled)\n\npca_df = pd.DataFrame(X_iris_2d, columns=[\"PC1\", \"PC2\"])\npca_df[\"species\"] = y_iris.map({0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"})\n\nfig, ax = plt.subplots(figsize=(6, 4.5))\nsns.scatterplot(data=pca_df, x=\"PC1\", y=\"PC2\", hue=\"species\", ax=ax)\nax.set_title(\"PCA Projection of Iris\")\nplt.show()\n\nprint(\"explained variance ratio:\", pca.explained_variance_ratio_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## まとめ\n\n- 教師あり学習: ラベルを使って予測器を作る（分類・回帰）\n- 教師なし学習: ラベルなしデータから構造を見つける（クラスタリング・次元圧縮）\n\n実務では、教師なしでデータの構造を把握してから、教師ありで予測モデルを構築する流れもよく使われます。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
