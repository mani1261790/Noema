<!doctype html>
<html lang="ja">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>vae</title>
  <link rel="stylesheet" href="/highlight/atom-one-dark.min.css" />
  <link rel="stylesheet" href="/katex/katex.min.css" />
  <style>
    :root {
      --bg-0: #f3f8fb;
      --bg-1: #d7e8f4;
      --bg-2: #f9f1e7;
      --text: #09162b;
      --muted: #44556f;
      --panel: rgba(255,255,255,.72);
      --border: rgba(255,255,255,.62);
      --code-bg: #09131a;
      --code-text: #e6f0f5;
      --shadow: 0 24px 54px rgba(10, 26, 54, 0.18), inset 0 1px 0 rgba(255,255,255,.62);
    }
    @media (prefers-color-scheme: dark) {
      :root {
        --bg-0: #071225;
        --bg-1: #0f2238;
        --bg-2: #1a2f44;
        --text: #ebf3ff;
        --muted: #9db3cf;
        --panel: rgba(12, 21, 40, 0.74);
        --border: rgba(145, 183, 227, 0.33);
        --code-bg: #040b17;
        --code-text: #e4efff;
        --shadow: 0 30px 66px rgba(2, 7, 16, 0.58), inset 0 1px 0 rgba(166,205,255,.16);
      }
    }
    * { box-sizing: border-box; }
    body {
      margin: 0;
      min-height: 100vh;
      padding: 2rem 1rem;
      color: var(--text);
      font-family: "IBM Plex Sans", system-ui, sans-serif;
      background:
        radial-gradient(circle at 12% 12%, rgba(87,196,223,.18), transparent 44%),
        radial-gradient(circle at 88% 5%, rgba(255, 155, 96, 0.16), transparent 40%),
        radial-gradient(circle at 80% 80%, rgba(109, 196, 255, 0.2), transparent 45%),
        linear-gradient(155deg, var(--bg-0) 0%, var(--bg-1) 48%, var(--bg-2) 100%);
    }
    main {
      max-width: 980px;
      margin: 0 auto;
      border-radius: 24px;
      border: 1px solid var(--border);
      background: var(--panel);
      backdrop-filter: blur(20px) saturate(145%);
      -webkit-backdrop-filter: blur(20px) saturate(145%);
      box-shadow: var(--shadow);
      padding: 1.25rem 1.25rem 1.5rem;
    }
    .prose-noema h1, .prose-noema h2, .prose-noema h3 {
      line-height: 1.25;
      margin-top: 1.25rem;
      margin-bottom: .65rem;
    }
    .prose-noema h1 { margin-top: .1rem; font-size: 1.8rem; }
    .prose-noema h2 { font-size: 1.35rem; }
    .prose-noema p {
      line-height: 1.85;
      color: var(--text);
      margin: .7rem 0;
    }
    .prose-noema ul, .prose-noema ol {
      margin: .7rem 0;
      padding-left: 1.4rem;
    }
    .prose-noema ul { list-style: disc; }
    .prose-noema ol { list-style: decimal; }
    .prose-noema li { margin: .28rem 0; line-height: 1.72; }
    .prose-noema a { color: inherit; text-underline-offset: 2px; }
    .prose-noema pre {
      background: var(--code-bg);
      color: var(--code-text);
      border-radius: 12px;
      padding: 1rem;
      overflow: auto;
      border: 1px solid rgba(255,255,255,.12);
    }
    .prose-noema code {
      font-family: "IBM Plex Mono", ui-monospace, SFMono-Regular, Menlo, monospace;
    }
    .prose-noema img {
      max-width: 100%;
      height: auto;
      border-radius: 10px;
    }
  </style>
</head>
<body>
  <main>
<article class="prose-noema">
<pre><code class="language-python">import math
import random
from statistics import mean

random.seed(33)</code></pre>
<h1 id="vae-variational-autoencoder">VAE（Variational Autoencoder）</h1>
<p>VAEは、オートエンコーダの「再構成能力」に、生成モデルとしての「サンプリング可能性」を加えたモデルです。潜在変数を確率分布で扱うことで、学習後に新しいデータを生成できるのが最大の特徴です。</p>

<p>まず、なぜ普通のオートエンコーダだけでは不十分かを整理します。</p>
<p>通常のAEは <code>x -&gt; z -&gt; x_hat</code> の再構成は上手でも、潜在空間 <code>z</code> がバラバラだと「どこからサンプルを引けば自然なデータが出るか」が分かりません。VAEはここに事前分布 <code>p(z)</code> を入れて、潜在空間を生成に使える形へ整えます。</p>

<h2 id="1-vaeの最小数式">1. VAEの最小数式</h2>
<p>VAEでは次の3つを同時に扱います。</p>
<ul>
<li>エンコーダ（近似事後分布）: <code>q_phi(z|x)</code></li>
<li>デコーダ（生成分布）: <code>p_theta(x|z)</code></li>
<li>潜在の事前分布: <code>p(z)=N(0,I)</code></li>
</ul>
<p>学習目標はELBO最大化で、次の2項に分かれます。</p>
<ul>
<li>再構成項: <code>E_{q_phi(z|x)}[log p_theta(x|z)]</code></li>
<li>正則化項: <code>KL(q_phi(z|x) || p(z))</code></li>
</ul>
<p>要するに、再構成を良くしつつ、潜在分布を標準正規に寄せる、という設計です。</p>

<pre><code class="language-python">def gaussian_log_prob(x, mu, var):
    var = max(var, 1e-8)
    return -0.5 * ((x - mu) ** 2 / var + math.log(2 * math.pi * var))


def kl_normal_to_standard(mu, logvar):
    # KL( N(mu, sigma^2) || N(0,1) )
    return 0.5 * (mu * mu + math.exp(logvar) - 1.0 - logvar)


x = 1.2
mu_dec = 1.0
var_dec = 0.3
mu_enc = 0.4
logvar_enc = -0.2

recon = gaussian_log_prob(x, mu_dec, var_dec)
kl = kl_normal_to_standard(mu_enc, logvar_enc)
elbo = recon - kl

print(&#39;reconstruction term =&#39;, round(recon, 4))
print(&#39;KL term             =&#39;, round(kl, 4))
print(&#39;ELBO                =&#39;, round(elbo, 4))</code></pre>
<h2 id="2-再パラメータ化トリック">2. 再パラメータ化トリック</h2>
<p><code>z ~ q_phi(z|x)</code> をそのままサンプリングすると、勾配が流しにくくなります。VAEでは</p>
<p><code>z = mu + sigma * eps, eps ~ N(0,1)</code></p>
<p>と書き換え、乱数を <code>eps</code> 側へ分離します。これにより <code>mu, sigma</code>（=ネットワーク出力）へ勾配を通せます。</p>

<pre><code class="language-python">def reparameterize(mu, logvar, eps):
    sigma = math.exp(0.5 * logvar)
    return mu + sigma * eps


mu = 0.7
logvar = -0.8
eps_samples = [random.gauss(0.0, 1.0) for _ in range(5)]
zs = [reparameterize(mu, logvar, e) for e in eps_samples]

print(&#39;eps samples =&#39;, [round(e, 3) for e in eps_samples])
print(&#39;z samples   =&#39;, [round(z, 3) for z in zs])</code></pre>
<h2 id="3-1次元トイデータでvaeを学習する">3. 1次元トイデータでVAEを学習する</h2>
<p>ここではPyTorchを使わず、あえて超小型モデルを手書きで最適化します。目的は、VAEの損失構造（再構成 vs KL）を体感することです。</p>
<ul>
<li>エンコーダ: <code>mu(x)=a*x+b</code>, <code>logvar(x)=c*x+d</code></li>
<li>デコーダ: <code>x_hat(z)=m*z+n</code></li>
</ul>
<p>学習は有限差分で行い、目的関数（再構成項 - beta * KL）を直接最大化します（教育用）。<br>
注意: このトイモデルは線形デコーダなので表現力を意図的に制限しています。2峰性データを完全に表現するのが目的ではなく、VAEの学習原理を確認するための設定です。</p>

<pre><code class="language-python">def make_toy_data(n1=60, n2=60):
    left = [random.gauss(-2.0, 0.45) for _ in range(n1)]
    right = [random.gauss(2.2, 0.55) for _ in range(n2)]
    return left + right


data = make_toy_data()
print(&#39;dataset size =&#39;, len(data))
print(&#39;mean(data)   =&#39;, round(mean(data), 3))
print(&#39;min/max      =&#39;, round(min(data), 3), round(max(data), 3))</code></pre>
<pre><code class="language-python">def encode(x, params):
    a, b, c, d, _, _ = params
    mu = a * x + b
    logvar = c * x + d
    logvar = max(min(logvar, 4.0), -6.0)  # 数値安定
    return mu, logvar


def decode(z, params):
    _, _, _, _, m, n = params
    return m * z + n


def elbo_dataset(data, params, beta=1.0, recon_var=0.25, eps_list=None):
    # recon_var: p_theta(x|z)=N(x_hat, recon_var) の固定分散
    # 小さいほど再構成誤差に厳しくなる
    if eps_list is None:
        # 通常のモンテカルロ近似では毎回epsをサンプルする
        eps_list = [random.gauss(0.0, 1.0) for _ in range(len(data))]

    recon_terms = []
    kl_terms = []
    objectives = []

    for x, eps in zip(data, eps_list):
        mu, logvar = encode(x, params)
        z = reparameterize(mu, logvar, eps)
        x_hat = decode(z, params)

        recon = gaussian_log_prob(x, x_hat, recon_var)
        kl = kl_normal_to_standard(mu, logvar)
        obj = recon - beta * kl

        recon_terms.append(recon)
        kl_terms.append(kl)
        objectives.append(obj)

    return mean(objectives), mean(recon_terms), mean(kl_terms)


params0 = [0.2, 0.0, -0.1, -0.5, 0.7, 0.0]
fixed_eps = [random.gauss(0.0, 1.0) for _ in range(len(data))]

obj0, recon0, kl0 = elbo_dataset(data, params0, beta=1.0, eps_list=fixed_eps)
print(&#39;initial objective =&#39;, round(obj0, 4))
print(&#39;initial recon=&#39;, round(recon0, 4), &#39;initial KL=&#39;, round(kl0, 4))</code></pre>
<pre><code class="language-python">def finite_diff_grad(data, params, beta, recon_var, eps_list, h=1e-3):
    grads = [0.0] * len(params)
    for i in range(len(params)):
        p_plus = params[:]
        p_minus = params[:]
        p_plus[i] += h
        p_minus[i] -= h

        f_plus, _, _ = elbo_dataset(data, p_plus, beta=beta, recon_var=recon_var, eps_list=eps_list)
        f_minus, _, _ = elbo_dataset(data, p_minus, beta=beta, recon_var=recon_var, eps_list=eps_list)
        grads[i] = (f_plus - f_minus) / (2 * h)
    return grads


def train_toy_vae(data, beta=1.0, steps=120, lr=0.03, recon_var=0.25):
    params = [0.2, 0.0, -0.1, -0.5, 0.7, 0.0]  # a,b,c,d,m,n

    # 有限差分のノイズを減らすため、共通乱数(common random numbers)でepsを固定
    eps_list = [random.gauss(0.0, 1.0) for _ in range(len(data))]

    trace = []
    for t in range(steps):
        grads = finite_diff_grad(data, params, beta, recon_var, eps_list)
        for i in range(len(params)):
            params[i] += lr * grads[i]  # objective最大化

        obj, recon, kl = elbo_dataset(data, params, beta=beta, recon_var=recon_var, eps_list=eps_list)
        trace.append((obj, recon, kl))

        if t % 20 == 0 or t == steps - 1:
            print(f&#39;step={t:03d} objective={obj:.4f} recon={recon:.4f} KL={kl:.4f}&#39;)

    return params, trace


params_beta1, trace_beta1 = train_toy_vae(data, beta=1.0, steps=140, lr=0.025, recon_var=0.30)
print(&#39;trained params (beta=1) =&#39;, [round(v, 4) for v in params_beta1])</code></pre>
<p>上のログで、目的関数（recon - beta * KL）が改善しつつ、再構成項とKL項のバランスが動くことが確認できます。これがVAE学習のダイナミクスです。</p>

<h2 id="4-beta-vaeでトレードオフを見る">4. beta-VAEでトレードオフを見る</h2>
<p><code>beta</code> を大きくするとKLを強く罰するため、潜在分布は事前分布に近づきます。その代わり再構成が悪化しやすくなります。</p>
<p>注意: <code>beta</code> を変えると目的関数そのものが変わるので、<code>objective</code> 値を横比較して優劣を決めるのは不適切です。比較は主に再構成項とKL項で行います。</p>

<pre><code class="language-python">params_beta4, trace_beta4 = train_toy_vae(data, beta=4.0, steps=140, lr=0.02, recon_var=0.30)

final1 = trace_beta1[-1]
final4 = trace_beta4[-1]

print(&#39;beta=1 final: objective={:.4f}, recon={:.4f}, KL={:.4f}&#39;.format(*final1))
print(&#39;beta=4 final: objective={:.4f}, recon={:.4f}, KL={:.4f}&#39;.format(*final4))</code></pre>
<pre><code class="language-python">def summarize_latent_stats(data, params):
    mus = []
    vars_ = []
    for x in data:
        mu, logvar = encode(x, params)
        mus.append(mu)
        vars_.append(math.exp(logvar))

    emu = mean(mus)
    emu2 = mean(m * m for m in mus)
    evar = mean(vars_)
    return emu, emu2, evar


mu1, mu21, var1 = summarize_latent_stats(data, params_beta1)
mu4, mu24, var4 = summarize_latent_stats(data, params_beta4)

print(&#39;latent summary beta=1: E[mu]=&#39;, round(mu1, 4), &#39;E[mu^2]=&#39;, round(mu21, 4), &#39;E[var]=&#39;, round(var1, 4))
print(&#39;latent summary beta=4: E[mu]=&#39;, round(mu4, 4), &#39;E[mu^2]=&#39;, round(mu24, 4), &#39;E[var]=&#39;, round(var4, 4))</code></pre>
<p><code>beta</code> を上げると、<code>q(z|x)</code> が標準正規に近づきやすくなり、潜在空間は整いますが、入力ごとの情報を削りすぎると再構成が崩れます。この綱引きを調整するのがbeta-VAEの本質です。</p>

<h2 id="5-生成と補間">5. 生成と補間</h2>
<p>学習後は <code>z ~ N(0,1)</code> を引いてデコーダに通すと新サンプルを生成できます。また、2つの入力の潜在平均を線形補間してデコードすると、連続的な変化を観察できます。</p>

<pre><code class="language-python">def generate_from_prior(params, n=8):
    out = []
    for _ in range(n):
        z = random.gauss(0.0, 1.0)
        x_hat = decode(z, params)
        out.append((z, x_hat))
    return out


gen = generate_from_prior(params_beta1, n=10)
print(&#39;samples from prior z~N(0,1):&#39;)
for z, xh in gen:
    print(&#39;z=&#39;, round(z, 3), &#39;-&gt; x_hat=&#39;, round(xh, 3))</code></pre>
<pre><code class="language-python">def latent_mean(x, params):
    mu, _ = encode(x, params)
    return mu

x_a = data[5]
x_b = data[-5]
mu_a = latent_mean(x_a, params_beta1)
mu_b = latent_mean(x_b, params_beta1)

print(&#39;x_a=&#39;, round(x_a, 3), &#39;mu_a=&#39;, round(mu_a, 3))
print(&#39;x_b=&#39;, round(x_b, 3), &#39;mu_b=&#39;, round(mu_b, 3))
print(&#39;interpolation in latent mean:&#39;)

for t in [0.0, 0.2, 0.4, 0.6, 0.8, 1.0]:
    z = (1 - t) * mu_a + t * mu_b
    x_hat = decode(z, params_beta1)
    print(&#39;t=&#39;, round(t, 1), &#39;z=&#39;, round(z, 3), &#39;x_hat=&#39;, round(x_hat, 3))</code></pre>
<h2 id="6-よくある失敗-posterior-collapse">6. よくある失敗: Posterior Collapse</h2>
<p>KLを強くしすぎたり、デコーダが強すぎたりすると、<code>q(z|x)</code> がほぼ <code>N(0,1)</code> になって入力情報を使わなくなることがあります。これをposterior collapseと呼びます。</p>
<p>対策としては、KL warm-up、free bits、デコーダ容量調整、学習率調整などが使われます。</p>
<p>注意: 実務での厳密判定は、KL値だけでは不十分です。<code>I(x;z)</code>（相互情報量）や、潜在をシャッフルしたときの再構成劣化など、情報保持の指標を併用します。ここで示す判定は教育用ヒューリスティックで、collapseの必要条件でも十分条件でもありません。</p>

<pre><code class="language-python"># collapse の簡易判定（toy）: KLが極端に小さく、再構成が悪化していないか
# 厳密判定ではなく、兆候を見るための簡易チェック（必要条件・十分条件ではない）
kl_beta1 = trace_beta1[-1][2]
kl_beta4 = trace_beta4[-1][2]
recon_beta1 = trace_beta1[-1][1]
recon_beta4 = trace_beta4[-1][1]

print(&#39;final KL beta=1 =&#39;, round(kl_beta1, 6), &#39;| recon=&#39;, round(recon_beta1, 6))
print(&#39;final KL beta=4 =&#39;, round(kl_beta4, 6), &#39;| recon=&#39;, round(recon_beta4, 6))

if kl_beta4 &lt; 0.01 and recon_beta4 &lt; recon_beta1 - 0.3:
    print(&#39;beta=4 run: collapse risk is high (toy criterion).&#39;)
else:
    print(&#39;beta=4 run: collapse risk is not extreme in this toy run.&#39;)

print(&#39;For strict diagnosis, add mutual-information or ablation-based checks.&#39;)</code></pre>
<p>VAEを一言で言うと、「再構成したい」という要求と「生成しやすい潜在空間にしたい」という要求を、ELBOで同時に満たすモデルです。</p>
<p>この後のGANや拡散モデルに進むときも、何を近似し、どの損失でその近似を押すのか、という観点で比較すると整理しやすくなります。</p>

</article>
  </main>
  <script src="/highlight/highlight.min.js"></script>
  <script>
    (function () {
      if (!window.hljs) return;
      document.querySelectorAll("pre code").forEach(function (block) {
        window.hljs.highlightElement(block);
      });
    })();
  </script>
</body>
</html>