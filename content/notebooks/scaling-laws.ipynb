{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スケーリング則\n",
    "\n",
    "LLMの事前学習では、モデルサイズ `N`、学習トークン数 `D`、計算資源 `C` を大きくすると、検証損失がべき乗的に下がる傾向があります。\n",
    "このノートでは、実験データからべき乗則を推定し、同一計算資源（isoflops）での最適配分を計算する流れを確認します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "よく使う近似は次の形です。\n",
    "\n",
    "`L(N, D) ≈ L_inf + a * N^{-alpha} + b * D^{-beta}`\n",
    "\n",
    "- `L_inf`: これ以上は下げにくい下限（不可約損失）\n",
    "- `alpha`, `beta`: モデル拡大・データ拡大の効き方\n",
    "\n",
    "まずは `N` と `D` をそれぞれ変えた観測データを作り、`alpha`, `beta` を推定します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 観測例（教育用の合成データ）\n",
    "N_million = np.array([30, 60, 120, 240, 480, 960], dtype=np.float64)   # million params\n",
    "D_billion = np.array([5, 10, 20, 40, 80, 160], dtype=np.float64)        # billion tokens\n",
    "\n",
    "# 実際の単位へ変換\n",
    "N_params = N_million * 1e6\n",
    "D_tokens = D_billion * 1e9\n",
    "\n",
    "# 生成側の真値（未知だと思って推定する）\n",
    "L_inf_true = 1.60\n",
    "A_true, alpha_true = 3.2, 0.37\n",
    "B_true, beta_true = 2.1, 0.29\n",
    "\n",
    "# 損失生成では見やすさのため M/B 単位でべき乗を作る\n",
    "rng = np.random.default_rng(7)\n",
    "L_of_N = L_inf_true + A_true * (N_million ** (-alpha_true)) + rng.normal(0, 0.01, size=N_million.shape)\n",
    "L_of_D = L_inf_true + B_true * (D_billion ** (-beta_true)) + rng.normal(0, 0.01, size=D_billion.shape)\n",
    "\n",
    "print('N sweep losses:', np.round(L_of_N, 4))\n",
    "print('D sweep losses:', np.round(L_of_D, 4))\n",
    "print('unit note: N uses params count, D uses token count in isoflops section')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2, 3.6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(N_million, L_of_N, marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('N (million params, log)')\n",
    "plt.ylabel('validation loss')\n",
    "plt.title('Loss vs Model Size')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(D_billion, L_of_D, marker='o', color='#d77f00')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('D (billion tokens, log)')\n",
    "plt.ylabel('validation loss')\n",
    "plt.title('Loss vs Data Size')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`L_inf` が未知なので、候補値を走査しながら\n",
    "`log(L - L_inf)` と `log(x)` の一次回帰で指数を推定します。\n",
    "\n",
    "`L_inf` は観測損失の最小値より少し小さい値にしかなりえないので、\n",
    "その近傍を候補として探索します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_power_with_fixed_floor(x, y, floor):\n",
    "    # y ~= floor + A * x^{-exponent}\n",
    "    z = y - floor\n",
    "    if np.any(z <= 0):\n",
    "        return None\n",
    "\n",
    "    lx = np.log(x)\n",
    "    lz = np.log(z)\n",
    "    # lz = c + m*lx, where m=-exponent\n",
    "    m, c = np.polyfit(lx, lz, 1)\n",
    "    pred = floor + np.exp(c) * (x ** m)\n",
    "    mse = float(np.mean((pred - y) ** 2))\n",
    "    return {\n",
    "        'floor': float(floor),\n",
    "        'A': float(np.exp(c)),\n",
    "        'exponent': float(-m),\n",
    "        'mse': mse,\n",
    "        'pred': pred,\n",
    "    }\n",
    "\n",
    "\n",
    "min_obs = float(min(np.min(L_of_N), np.min(L_of_D)))\n",
    "floor_candidates = np.linspace(min_obs - 0.25, min_obs - 1e-4, 400)\n",
    "\n",
    "best = None\n",
    "for floor in floor_candidates:\n",
    "    fN = fit_power_with_fixed_floor(N_million, L_of_N, floor)\n",
    "    fD = fit_power_with_fixed_floor(D_billion, L_of_D, floor)\n",
    "    if fN is None or fD is None:\n",
    "        continue\n",
    "    total_mse = fN['mse'] + fD['mse']\n",
    "    if best is None or total_mse < best['total_mse']:\n",
    "        best = {\n",
    "            'L_inf': float(floor),\n",
    "            'N_fit': fN,\n",
    "            'D_fit': fD,\n",
    "            'total_mse': float(total_mse),\n",
    "        }\n",
    "\n",
    "fit_joint = best\n",
    "print('Shared-floor fit summary:')\n",
    "print('L_inf =', round(fit_joint['L_inf'], 5), 'total_mse =', round(fit_joint['total_mse'], 7))\n",
    "print('N_fit =', {k: round(v, 5) for k, v in fit_joint['N_fit'].items() if k != 'pred'})\n",
    "print('D_fit =', {k: round(v, 5) for k, v in fit_joint['D_fit'].items() if k != 'pred'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2, 3.5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(N_million, L_of_N, label='observed')\n",
    "plt.plot(N_million, fit_joint['N_fit']['pred'], label='power fit', color='#cc3344')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('N (M params)')\n",
    "plt.ylabel('loss')\n",
    "plt.title(f\"alpha≈{fit_joint['N_fit']['exponent']:.3f}\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(D_billion, L_of_D, label='observed')\n",
    "plt.plot(D_billion, fit_joint['D_fit']['pred'], label='power fit', color='#cc3344')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('D (B tokens)')\n",
    "plt.ylabel('loss')\n",
    "plt.title(f\"beta≈{fit_joint['D_fit']['exponent']:.3f}\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に isoflops を考えます。\n",
    "デコーダ型学習の粗い近似として `C ≈ 6ND`（`N`: パラメータ数, `D`: 学習トークン数）を使います。\n",
    "\n",
    "`D = C/(6N)` を `L(N, D)` に代入すると\n",
    "`f(N) = aN^{-alpha} + b(C/6)^{-beta}N^{beta}` になり、\n",
    "これを `df/dN = 0` で解くと `N*` と `D*` が得られます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 共有L_infで推定した係数を使って、L(N,D)=L_inf+aN^-alpha+bD^-beta を最適化\n",
    "L_inf = fit_joint['L_inf']\n",
    "a_fit, alpha = fit_joint['N_fit']['A'], fit_joint['N_fit']['exponent']\n",
    "b_fit, beta = fit_joint['D_fit']['A'], fit_joint['D_fit']['exponent']\n",
    "\n",
    "# a_fit,b_fit は N(M params), D(B tokens) の単位で推定されているので\n",
    "# isoflops (N: params, D: tokens) へ合わせて係数を変換する\n",
    "# (N/1e6)^-alpha = (1e6^alpha) * N^-alpha\n",
    "# (D/1e9)^-beta  = (1e9^beta)  * D^-beta\n",
    "a_raw = a_fit * (1e6 ** alpha)\n",
    "b_raw = b_fit * (1e9 ** beta)\n",
    "\n",
    "\n",
    "def optimal_N_D_for_compute(C, a, alpha, b, beta):\n",
    "    # C = 6ND -> D = C/(6N)\n",
    "    # minimize f(N)=aN^-alpha + b(C/6)^-beta N^beta\n",
    "    numer = a * alpha\n",
    "    denom = b * beta\n",
    "    N_star = (numer / denom) ** (1.0 / (alpha + beta)) * (C / 6.0) ** (beta / (alpha + beta))\n",
    "    D_star = C / (6.0 * N_star)\n",
    "    return N_star, D_star\n",
    "\n",
    "\n",
    "# C の単位は FLOPs 相当の抽象値（ここでは比較目的）\n",
    "C_values = np.logspace(18, 22, 9)\n",
    "N_star = []\n",
    "D_star = []\n",
    "for C in C_values:\n",
    "    n, d = optimal_N_D_for_compute(C, a_raw, alpha, b_raw, beta)\n",
    "    N_star.append(n)\n",
    "    D_star.append(d)\n",
    "N_star = np.array(N_star)\n",
    "D_star = np.array(D_star)\n",
    "\n",
    "print('first 4 optimal pairs (N*, D*):')\n",
    "for i in range(4):\n",
    "    print(f\"C={C_values[i]:.1e} -> N*={N_star[i]/1e6:.2f}M params, D*={D_star[i]/1e9:.2f}B tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7.2, 3.6))\n",
    "plt.plot(C_values, N_star / 1e6, marker='o', label='optimal N* (M params)')\n",
    "plt.plot(C_values, D_star / 1e9, marker='s', label='optimal D* (B tokens)')\n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Compute C (log)')\n",
    "plt.ylabel('Optimal scale (log)')\n",
    "plt.title('Isoflops-optimal allocation')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実務でありがちな失敗は、計算資源が同じなのに\n",
    "- モデルだけ大きくしてデータ不足（undertrained）\n",
    "- データだけ増やしてモデル不足（underparameterized）\n",
    "\n",
    "になることです。下で同一 `C` に対する損失差を比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_loss(N, D, L_inf, a, alpha, b, beta):\n",
    "    return L_inf + a * (N ** (-alpha)) + b * (D ** (-beta))\n",
    "\n",
    "\n",
    "ratios = [0.5, 1.0, 2.0]  # Nを最適比の何倍にするか\n",
    "example_C = 1e20\n",
    "n_opt, d_opt = optimal_N_D_for_compute(example_C, a_raw, alpha, b_raw, beta)\n",
    "\n",
    "print(f'compute C={example_C:.1e}')\n",
    "print(f'optimal N={n_opt/1e6:.2f}M params, D={d_opt/1e9:.2f}B tokens')\n",
    "\n",
    "for r in ratios:\n",
    "    n = n_opt * r\n",
    "    d = example_C / (6.0 * n)\n",
    "    L = approx_loss(n, d, L_inf, a_raw, alpha, b_raw, beta)\n",
    "    label = 'optimal' if abs(r - 1.0) < 1e-9 else f'N x {r}'\n",
    "    print(f'{label:8s}: N={n/1e6:8.2f}M, D={d/1e9:8.2f}B, approx loss={L:.5f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "スケーリング則は万能ではありません。\n",
    "データ品質、ドメインミスマッチ、最適化設定、アーキテクチャ変更で指数や下限は変わります。\n",
    "それでも、実験計画の初期段階で「どこに計算資源を使うか」を決める強力な指針になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 価格の粗い見積もり（仮定値）\n",
    "train_flops = 3.0e22\n",
    "hardware_tflops = 250.0   # 1 GPUあたり\n",
    "num_gpus = 64\n",
    "utilization = 0.35\n",
    "\n",
    "seconds = train_flops / (hardware_tflops * 1e12 * num_gpus * utilization)\n",
    "hours = seconds / 3600\n",
    "\n",
    "print('Estimated wall-clock hours:', round(hours, 2))\n",
    "\n",
    "usd_per_gpu_hour = 1.8\n",
    "cost = hours * num_gpus * usd_per_gpu_hour\n",
    "print('Estimated training cost (USD, rough):', round(cost, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このノートで押さえたい実務ポイント:\n",
    "\n",
    "1. まず小規模スイープで `alpha, beta, L_inf` を推定する\n",
    "2. その推定に基づき isoflops で `N` と `D` を配分する\n",
    "3. 本番では品質劣化要因（データ品質・最適化不安定）を別監視する\n",
    "\n",
    "この3段階を回すと、計算予算の無駄打ちを減らしやすくなります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}