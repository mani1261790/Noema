{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# スコアベースモデルと拡散モデル\n\nスコアベースモデルと拡散モデルでは、生成の仕組みを抽象用語で終わらせず、毎段階をコードで確認します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 概念の土台\n\nスコアベースモデルと拡散モデルに入る前に、つまずきやすい用語を先にそろえます。以降のコードでは、変数がどの概念を表しているかを対応付けながら読んでください。\n\n- **確率分布**: データがどの値を取りやすいかを表す規則です。生成モデルの土台です。\n- **サンプリング**: 分布から実際のデータ点を取り出す操作です。生成結果そのものに対応します。\n- **目的関数**: 学習で最適化する指標です。モデルの学習挙動を決めます。\n- **スコア**: 対数密度の勾配です。高密度方向を示します。\n- **ノイズスケジュール**: 拡散過程でノイズ量を時刻ごとに決める設計です。\n\nこのノートでは、ここで定義した語を実験セルの変数・式に直接対応させて確認します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 観察 1: 拡散向けノイズ初期化\n\nスコアベースモデルではノイズ段階が鍵です。初期ノイズ列を作ります。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\nrandom.seed(31)\nz = [round(random.gauss(0, 1.2), 3) for _ in range(5)]\nprint('task = score-diffusion-models')\nprint('latent z =', z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "ノイズから復元する流れをここから追跡します。\n\nこの節では、潜在変数 が入出力のどこを決めるかを中心に読める状態になれば十分です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 観察 2: 単純なデコーダを書く\n\n次に、潜在変数を観測空間へ写像する簡易デコーダを作ります。生成モデルの基本構造をコードで可視化します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weights = [1.4, -0.6, 0.8, 0.5, -1.1]\nbias = 0.2\nx_hat = sum(zi * wi for zi, wi in zip(z, weights)) + bias\nprint('decoded scalar =', round(x_hat, 5))\nprint('abs scale =', round(abs(x_hat), 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "実際の生成モデルは高次元ですが、構造は同じです。潜在を観測へ写像し、再構成品質を改善します。\n\nこの節では、潜在変数 が入出力のどこを決めるかを中心に読める状態になれば十分です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 計算の対応表\n\n1. $s_t(x) = \\nabla_x\\log p_t(x)$\n2. $dx = f(x,t)\\,dt + g(t)\\,dw$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 観察 3: ノイズを加えて復元する\n\nここで、拡散系モデルの直感を最小実験で確認します。ノイズ付加と復元の往復を短いコードで体験します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x0 = 1.5\nbeta = 0.12\nnoise = -0.3\nxt = ((1 - beta) ** 0.5) * x0 + (beta ** 0.5) * noise\nx0_hat = (xt - (beta ** 0.5) * noise) / ((1 - beta) ** 0.5)\nprint('x0, xt, x0_hat =', round(x0, 5), round(xt, 5), round(x0_hat, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "復元誤差を観察すると、ノイズスケジュールの意味が見えてきます。理論と実装をつなぐ重要な観測点です。\n\nこの節では、潜在変数 が入出力のどこを決めるかを中心に読める状態になれば十分です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 観察 4: 混合分布の感覚を作る\n\n次に、複数モードを持つ分布を手で作ります。モード崩壊の議論に入る前の下地として有効です。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mix = [(-2.0, 0.4), (1.5, 0.6)]\nsamples = []\nfor m, w in mix:\n    samples.append(round(m + (w * 0.1), 3))\nprint('mode-aware samples =', samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "混合分布の直感があると、生成結果の『多様性』を定量評価する発想が自然になります。\n\nこの節では、潜在変数 が入出力のどこを決めるかを中心に読める状態になれば十分です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 観察 5: 学習指標を定義する\n\n最後に、生成品質を観察する最小指標を作ります。見た目だけで判断しない習慣を作ることが狙いです。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recon_errors = [0.42, 0.31, 0.29, 0.36, 0.33]\navg = sum(recon_errors) / len(recon_errors)\nworst = max(recon_errors)\nbest = min(recon_errors)\nprint('avg/best/worst =', round(avg, 4), round(best, 4), round(worst, 4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "平均値と外れ値を同時に見ると、モデルが安定しているかを判断しやすくなります。\n\nこの節では、潜在変数 が入出力のどこを決めるかを中心に読める状態になれば十分です。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 要点整理\n\n今回のノートで押さえておくべき誤解しやすい点を整理します。\n\n1. 見た目の良さだけで比較してしまう\n2. 多様性と品質のトレードオフを観測しない\n3. ノイズスケジュールの意味を理解しないまま調整する\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
